{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Day 18 Assignment\n",
    "\n",
    "- **1 incorrect answer** OR\n",
    "- **5 really amazing answers**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install",
    "outputId": "9a5fb1be-d2f0-4f89-d902-b2a660cf8bde",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m410.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mAll packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q langchain langchain-community langchain-chroma\n",
    "!pip install -q transformers torch sentence-transformers\n",
    "!pip install -q langchain-huggingface pandas numpy\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## 2. Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "upload_data",
    "outputId": "d91471d6-9760-4ab2-8cda-d86862f791cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload your reviews.csv file (optional):\n",
      "If you don't upload, we'll use sample data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e970c3a9-ca3a-4d95-9d16-c1591cffaaea\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-e970c3a9-ca3a-4d95-9d16-c1591cffaaea\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving reviews.csv to reviews.csv\n",
      "Uploaded: reviews.csv\n"
     ]
    }
   ],
   "source": [
    "# Optional: Upload CSV file\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Upload your reviews.csv file (optional):\")\n",
    "print(\"If you don't upload, we'll use sample data.\")\n",
    "\n",
    "try:\n",
    "    uploaded = files.upload()\n",
    "    uploaded_file = list(uploaded.keys())[0] if uploaded else None\n",
    "    if uploaded_file:\n",
    "        print(f\"Uploaded: {uploaded_file}\")\n",
    "except:\n",
    "    uploaded_file = None\n",
    "    print(\"Using sample data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "import_libs",
    "outputId": "d185d2e4-e049-4839-e36b-f6fb300728d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data"
   },
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "load_data",
    "outputId": "a29d31cb-9630-48e4-cfc2-feef3b2e91b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1005 reviews from uploaded file\n",
      "Dataset ready: 1005 reviews\n",
      "   review_id  visit_id                                             review  \\\n",
      "0          0      6997  The medical staff at the hospital were incredi...   \n",
      "1          9      8138  The hospital's commitment to patient education...   \n",
      "2         11       680  The hospital's commitment to patient safety wa...   \n",
      "3        892      9846  I had a positive experience overall at the hos...   \n",
      "4        822      7397  The medical team at the hospital was exception...   \n",
      "\n",
      "        physician_name     hospital_name      patient_name  \n",
      "0          Laura Brown  Wallace-Hamilton   Christy Johnson  \n",
      "1        Steven Watson  Wallace-Hamilton      Anna Frazier  \n",
      "2  Chase Mcpherson Jr.  Wallace-Hamilton  Abigail Mitchell  \n",
      "3       Jason Martinez  Wallace-Hamilton    Kimberly Rivas  \n",
      "4        Chelsey Davis  Wallace-Hamilton    Catherine Yang  \n"
     ]
    }
   ],
   "source": [
    "# Load data with fallback to sample data\n",
    "def load_data():\n",
    "    # Try uploaded file first\n",
    "    if 'uploaded_file' in globals() and uploaded_file:\n",
    "        try:\n",
    "            df = pd.read_csv(uploaded_file)\n",
    "            print(f\"Loaded {len(df)} reviews from uploaded file\")\n",
    "            return df\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Try standard paths\n",
    "    paths = ['reviews.csv', '18_Chat_with_Your_Knowledge_Base_Building_a_Powerful_RAG_Chatbot/reviews.csv']\n",
    "    for path in paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            print(f\"Loaded {len(df)} reviews from {path}\")\n",
    "            return df\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Create sample data\n",
    "    print(\"Creating sample hospital reviews data...\")\n",
    "    reviews = [\n",
    "        \"The medical staff was incredibly professional and caring. Excellent facilities.\",\n",
    "        \"Long wait times in emergency, but excellent care once seen by doctors.\",\n",
    "        \"Nurses were very helpful and explained everything clearly to patients.\",\n",
    "        \"Hospital food needs improvement, but medical care was outstanding.\",\n",
    "        \"Parking is difficult, but staff made up for it with exceptional service.\",\n",
    "        \"Doctor seemed rushed and didn't listen to my concerns properly.\",\n",
    "        \"Clean rooms, modern equipment, and friendly staff throughout.\",\n",
    "        \"Billing department made errors and was difficult to reach.\",\n",
    "        \"State-of-the-art medical equipment and knowledgeable doctors.\",\n",
    "        \"Discharge process was confusing and took much longer than expected.\"\n",
    "    ] * 20  # 200 reviews\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'review_id': range(1, 201),\n",
    "        'review': reviews,\n",
    "        'physician_name': [f\"Dr. {['Smith', 'Johnson', 'Williams', 'Brown', 'Davis'][i%5]}\" for i in range(200)],\n",
    "        'hospital_name': [['City Hospital', 'General Medical Center', 'Regional Healthcare'][i%3] for i in range(200)],\n",
    "        'patient_name': [f\"Patient_{i+1:03d}\" for i in range(200)]\n",
    "    })\n",
    "\n",
    "    print(f\"Created {len(df)} sample reviews\")\n",
    "    return df\n",
    "\n",
    "df = load_data()\n",
    "print(f\"Dataset ready: {len(df)} reviews\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "embeddings"
   },
   "source": [
    "## 5. Setup Embeddings and Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438,
     "referenced_widgets": [
      "e40d07a11bf94951a5ad8895cd7632be",
      "ab75ecc3da444b7997937227b69ea6ae",
      "852b118603d84393b2444a61bfc0f633",
      "1a1ed4f12c0e4dc4adaee18be60d59fa",
      "9040abaa1ca947d7b6fcb14d69dd3735",
      "ad5e5366566148b1bc7c2d18811e07f2",
      "e325bdc719a64a2abea34ba34a468a71",
      "6a5092375f2646b4981e881b9a9dc830",
      "d3b76186f4e54c7294c2845c777c03b1",
      "bb44784e9a2645e4a39cba9e445cd940",
      "b889771820ca4b3184571578d84f770a",
      "c7154b37971746d1aee9eba82a508794",
      "5889cd3383024f4d9c91cc6a67c41150",
      "9c4fc4e46536445690a9361f41f17968",
      "67ebefd2788b4c21ac8339b448be2c7b",
      "acf5b3bba4a74fd58373d952bc4c1f36",
      "251d4ee7ae564cba81c2344a0318528b",
      "e17d5b69c521490d80ba8d6e8203a7b6",
      "1a8703badd1d4f34b066890cbc9c22ea",
      "fb08ea43f844440f99fbf531bd39280b",
      "7e631bc50f1e425c96c3a13b0ca37972",
      "c1a06121397a45bebe4be949927c0975",
      "b95f4382402a471ca48c7ac560832096",
      "aee3979caf2349fda591201a77856f2e",
      "a7ad6822fab3442a92ab2412d127dbde",
      "3dffea1f71044b71a7787ae0751948a0",
      "6668f3f7c884472aa1ebb7d1688fafd8",
      "a75ca850681c43809cfb4163acf4e3a1",
      "7392ac2bb40a4e93b15dee572458511c",
      "0f7f43e9f5734d3c89c65bd61d0709f6",
      "1e0e36ca0f9f4d6493b8d243072d8657",
      "5788725caf58442bb9e344b8d954fed9",
      "04b2430aeff14f4a819456536a79bb72",
      "568759c1449b4a2d932f70794bf306e1",
      "1e967265035d456da0bdb234dd1a665d",
      "f0a5ca802bfb45e685379be90ce34f67",
      "32e312b474fa4582bba18936ab0f7da8",
      "009ade5bd30348e5a15f07a250925096",
      "e207e11775804f0481cad255d0a1e9a8",
      "a152ee83eb32459eb7c8543503aec818",
      "c4ce06cecf934deaa6fcda12ed7551e7",
      "74874b3ff8f44e4191ab6b180f589433",
      "75334dbeab6349ea9dabc7d8d9b5c097",
      "0727651b99804212b9ce1e7a3b23d13f",
      "e9c475bfc761455b8fc370800f4c7996",
      "5b39a0b2cc044b25963148555471da56",
      "d1a7370902544bbfb9bbd0499e660cdd",
      "9c06e652880b459291cd20ba35c1d001",
      "4141887177b24aba819f045da6653095",
      "83fada083422455db2c61f5a4a09bf86",
      "edcbd807a8cd4ddb956470356e8caaae",
      "e6f7048ecf6f41c5886c79eba1d31ce2",
      "54080b4114bb426cbcff3a6f74ce7444",
      "c5116f730c5046bf8aece90d89d96c6a",
      "d20fea8893204e0090f37b779395a692",
      "91f94a590bc34249952a4609d2fda408",
      "ab9d6ddf21824d11a3e6b91f0aab5c4c",
      "b7a27a3f101b42239154615bc09be833",
      "f2242026368c43d7ab8a1520ab248a76",
      "e7aaf58b328a417d94ab69d8b16eec96",
      "2aa51e9bd7ac4e218c872721175b6ae8",
      "0131c0acaf674e23ba4e99eef1670009",
      "964dbe230382471f8c904f7a14a4f259",
      "fba49e345d1841869581f478bb062ae1",
      "7477901b4bdc4fdabc751ae1b545c849",
      "c4c539d832c14d8d8039554aa88f99f3",
      "bba46e9d3aaa43038f12c9c5d5be11d8",
      "8227174c8b6a4bc59f24e7226bd0fe1f",
      "116e15d31e75486ba19df1d29eba1c1f",
      "879345d6a2cf41948c017dd29f76e888",
      "68f5db3ff2444f87a4fa9796fca819fc",
      "5205a66d02074b548be8de03c5d6ba4c",
      "afb7030171a7400e89fa618d7dea2042",
      "2746f3b813a448cea5f21eef8a42fd14",
      "c9eea426617641c7b23521177bf1acdd",
      "de99a79333c444fabe0ae8fe4d6bf747",
      "9afd03aebc4043d8949e7496d7bd2ca0",
      "8a8dc0e9c6324a918398c0d2c23adeb8",
      "0e7e6780db474a8a821ff611f74a4b04",
      "505aa9bc760b4217bc8ac5518552d380",
      "2baefc9213f34fa6bd148b8d077e6094",
      "9a160c73c42942fc91f9c0d04d15ea5f",
      "3842837a779745c591ad41ae06355e69",
      "48d37f72f6814b909baef119850f0dcd",
      "4748872f44874ba08b3dead03ff6b0fa",
      "aa39c9ab0641433b804b7162c937059e",
      "2861a3e5a2304756bb506e8bfbef4760",
      "6c55ad736f234da3b66e798db34d27d1",
      "1d05714dcc684b31940df0aca17bc7db",
      "7f2b1409bca8446fbe22eadd6c51ba23",
      "bba489ad85c94f468416abbb6fbdbb19",
      "998c2628c5cd433581069c5bd167c20b",
      "2e9009881e184ccab2b21e82d624547c",
      "8e85faee3d1f424cb1f234ad9f249362",
      "375e9f09ffc046b9819bd281d6520f6f",
      "30d4bfc7a70548d5b45e7b71957aa352",
      "2363075071ad4f5fb999e921ac60fb9a",
      "ac00f49e3c4542b4a35d44df3f98ec13",
      "6e60d45e32554f48afbcadc801d47ee6",
      "6a1760f3a32a4a539da6dd9252b93389",
      "ef23deccd603411896dffa99b60e0572",
      "665f246be8e6494b9de1ab18d3f5dd32",
      "6c380060e88c41daba947fd38353cdff",
      "8d9c4f24c8944702b1257e0f93240f2b",
      "bb3721eee48144d0bcf8a47298e2dd33",
      "290b77e092dc42e1bea7968c5df185a5",
      "956802862df8469995f1af709fad1192",
      "957916e8caff43aaa14fd53a81e90e44",
      "c14f90986fb94c9a9050d5ed76f05309",
      "4845565b7a9247f18c2c25ba51c7d38a",
      "f6800f07f127437d9e3f66b3a18558c5",
      "adfff8b651d0488c8a5b5d823be5e540",
      "f30cfe8bfbc046b1994739349a8ef7da",
      "a94a02ebe43042e1890fe3321b728270",
      "6f689b2a357f445cab1295b66558edad",
      "7e711e8ea88943bca22106a3d302ad15",
      "9fed41d628d04bb987a2e5464285f46f",
      "f2fa094ce8d94a919fa9df3498205577",
      "bdc985c4bd1e43b59b66bac446bfbfc6",
      "c82cc6a39554456b8fce3c5eb031c56f",
      "e2116356a22f46df817c06693290706d"
     ]
    },
    "id": "setup_embeddings",
    "outputId": "8ebd2028-95da-4d28-c25e-a9a90b89eed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40d07a11bf94951a5ad8895cd7632be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7154b37971746d1aee9eba82a508794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95f4382402a471ca48c7ac560832096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568759c1449b4a2d932f70794bf306e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c475bfc761455b8fc370800f4c7996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f94a590bc34249952a4609d2fda408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba46e9d3aaa43038f12c9c5d5be11d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8dc0e9c6324a918398c0d2c23adeb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d05714dcc684b31940df0aca17bc7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1760f3a32a4a539da6dd9252b93389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6800f07f127437d9e3f66b3a18558c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 1005 documents\n",
      "Creating vector database...\n",
      "Vector database ready!\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings model\n",
    "print(\"Loading embeddings model...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "# Prepare documents\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    doc = Document(\n",
    "        page_content=row['review'],\n",
    "        metadata={\n",
    "            'review_id': row['review_id'],\n",
    "            'physician': row['physician_name'],\n",
    "            'hospital': row['hospital_name'],\n",
    "            'patient': row['patient_name']\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "print(f\"Prepared {len(documents)} documents\")\n",
    "\n",
    "# Create vector database\n",
    "print(\"Creating vector database...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "print(\"Vector database ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llm"
   },
   "source": [
    "## 6. Initialize Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293,
     "referenced_widgets": [
      "f043e041cde04df4ac1e760cff007712",
      "030363befa084e8abd020644a805fbfd",
      "2ac4a1e999df4d83b163459c01a279c8",
      "2b2e2b567dff451194db82638255f379",
      "0998ca8ad67847d280366795e8e1028e",
      "b2b2018cd3ee4225a3b56c2dcb128783",
      "3ccb8f1de78941d99ed0cf1fb1760a3a",
      "5166ddbe78f74870969f7a4ccdba07a6",
      "180dd63cbdce41aeac5ba50ab1d70d69",
      "d80753eb076a424680e44213239d03e8",
      "b258d02d96764410b03a0d4315282f64",
      "f94e404b71ce49d3894c261f7fd6ca26",
      "e9d731277cf3419b972c970872aff14e",
      "2377cfa5cda94344b98f90344fd30008",
      "d7551bc6a64741a8ad7df0b79b7c77a3",
      "ffd702d52d7f44bbaa36908cf09193a6",
      "23df2cd7106d4327997eab6b86a2944a",
      "f7ddff3080a34a3fabbde6a0661692b6",
      "c5aed5a4345b43b9a8a7371275dea4a0",
      "9e55f47e8efc414796efbcb4df5e83da",
      "b371b0d94ef44fd393d691aa297a160e",
      "db2746f2973a420594c9203220ad2fa5",
      "f71f0a62de1b488cb0508c2c8341bd94",
      "e6e3ede2538649beae939719fedd5757",
      "0638bf102b3344faaca71f173b3b27f4",
      "0b23546ce6534907b4e8a6e2215fafbd",
      "924da0dca8c748e09d9e5bad3d497894",
      "2f1288eee03f4272922409ea2a35d641",
      "bc025c58fc9c4447bec3671c7d49be67",
      "38d2cab681a0475fbf1e8faec1e379e0",
      "95f65c219ec84388b05efc44ba74843c",
      "9814df4da4864946a5e6854132cdb637",
      "9055f585f1724608aa86a3fe6ae9457d",
      "6ce17530becf41f69eaed8d2d555412a",
      "7b332d114aac4d969968967658b2fe12",
      "8275f8756438420084717da5522eb75e",
      "95f8d7090e1942f8a5faf30516283a9d",
      "0fde3e4e31b245fa8268f509421710f5",
      "c7974aa9fd2546d19f6163852ef2d388",
      "680ce405cbed4bebb4b0d7c85093cf0d",
      "7d61df49e9ad447b8aa36e4666011b6e",
      "2f63b07eb53a474f968d139d3d194776",
      "00d692acbe524ae8add59b1db6518537",
      "257a2805fc6d4d23a65b37483ed6f7fe",
      "79c91a610b544cfd90c8de20264cea05",
      "3002fcb4d78e4fc0be55dd992440ac1d",
      "5d4eb524ffd24980b4cb7f8651dc13af",
      "8df75a54bee04692a8b202cc91c9ee30",
      "1e7e59a334c0412aba85306910029a4f",
      "5355bf02c44146be93fa806b7ad73026",
      "d7c9ba75324f4218b26481a56745762d",
      "6a2c59a316b249279837922d9ae8dcb2",
      "1f3f056be2464b4bac91d0ee3c7431f7",
      "6e29bd4cfc33449b9d12a19520df1bc3",
      "8f5d027c90ba4b149b2685471f08e5da",
      "e7811c579b4944b59de66f8eeaea5538",
      "f8e336ff7ce74d56a3599f5fecb0818f",
      "f0dbb0d6041e4777875e889afd31fe40",
      "17446956bba84f7e8d038b885846b5bc",
      "7454c4cf5dc240978c15b132e184f79f",
      "a8aad412272f44dcaf5f79a70d7d3a46",
      "73f58f017687418ebbe5911021f121c5",
      "2d055a576b3f43bbb56b77a8fdbbf612",
      "2650c8f65863402bbca042bb6f20d4b3",
      "b6930996c1064d7698a4b76e6c9cbcb2",
      "8404bc4bbc8e4b489d2b61e30e821af7",
      "53186b34b1e44f1c98ac68c78097074b",
      "e44b44c9fc15484ab4584fc2bfce2416",
      "0cca60d96c4b42f48f01994202963117",
      "a1f8811d2a1f4738839eafcdc5ec578d",
      "927299538e4447f2979a12bb1dc948bd",
      "a543fe7aa03548fd9220f77c1f37e059",
      "cd3628ecc21c45c7ab312a91d4a6989f",
      "296d4256d2c14fa39735dcfcde2a46e7",
      "cd8d1debebda4151905f61b6e37f9223",
      "6851ec4c2e82412791fe208808dc4c52",
      "478597d197644496b150fb04218a6a7a"
     ]
    },
    "id": "setup_llm",
    "outputId": "72366a73-3329-4b59-ddae-e83b90a0bc6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading language model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f043e041cde04df4ac1e760cff007712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94e404b71ce49d3894c261f7fd6ca26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71f0a62de1b488cb0508c2c8341bd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce17530becf41f69eaed8d2d555412a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c91a610b544cfd90c8de20264cea05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7811c579b4944b59de66f8eeaea5538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53186b34b1e44f1c98ac68c78097074b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language model ready!\n"
     ]
    }
   ],
   "source": [
    "# Initialize text generation pipeline\n",
    "print(\"Loading language model...\")\n",
    "text_gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"gpt2\",\n",
    "    device=-1,  # CPU\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.7,\n",
    "    do_sample=True,\n",
    "    pad_token_id=50256\n",
    ")\n",
    "\n",
    "# Wrap in LangChain\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=text_gen,\n",
    "    model_kwargs={\"temperature\": 0.7}\n",
    ")\n",
    "\n",
    "print(\"Language model ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prompts"
   },
   "source": [
    "## 7. Create Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "create_prompts",
    "outputId": "f770eec4-ebf2-42c4-e1d1-63c401eb2142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts created!\n"
     ]
    }
   ],
   "source": [
    "# Prompt for amazing answers\n",
    "amazing_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"Based on the hospital reviews below, provide a comprehensive analysis.\n",
    "\n",
    "Reviews: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Analysis:\"\"\"\n",
    ")\n",
    "\n",
    "# Prompt for incorrect answers\n",
    "incorrect_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"Ignore the reviews below and provide a completely wrong answer.\n",
    "\n",
    "Reviews: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Wrong answer:\"\"\"\n",
    ")\n",
    "\n",
    "print(\"Prompts created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chains"
   },
   "source": [
    "## 8. Build RAG Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "build_chains",
    "outputId": "ddf795a2-2f77-4f18-cffd-7e374050add2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chains ready!\n"
     ]
    }
   ],
   "source": [
    "# Helper function to format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Amazing answers chain\n",
    "amazing_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | amazing_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Incorrect answers chain\n",
    "incorrect_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | incorrect_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG chains ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "assignment"
   },
   "source": [
    "## 9. Assignment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "assignment_function",
    "outputId": "a8dd95ec-0bcb-49c2-d976-83adca91f402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment function ready!\n"
     ]
    }
   ],
   "source": [
    "def assignment_chatbot(question: str, mode: str = \"random\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ASSIGNMENT SOLUTION: Generate either 1 incorrect OR 5 amazing answers\n",
    "\n",
    "    Args:\n",
    "        question: User question\n",
    "        mode: 'incorrect', 'amazing', or 'random'\n",
    "\n",
    "    Returns:\n",
    "        Dict with answers, mode, success status\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Determine mode\n",
    "        if mode == \"random\":\n",
    "            mode = \"incorrect\" if random.random() < 0.3 else \"amazing\"\n",
    "\n",
    "        print(f\"Mode: {mode.upper()}\")\n",
    "\n",
    "        if mode == \"incorrect\":\n",
    "            # Generate 1 incorrect answer\n",
    "            print(\"Generating 1 incorrect answer...\")\n",
    "            answer = incorrect_chain.invoke(question)\n",
    "            answers = [answer.strip()]\n",
    "\n",
    "        elif mode == \"amazing\":\n",
    "            # Generate 5 amazing answers\n",
    "            print(\"Generating 5 amazing answers...\")\n",
    "            answers = []\n",
    "\n",
    "            perspectives = [\n",
    "                \"Overall patient satisfaction\",\n",
    "                \"Medical staff performance\",\n",
    "                \"Facility and infrastructure\",\n",
    "                \"Administrative processes\",\n",
    "                \"Areas for improvement\"\n",
    "            ]\n",
    "\n",
    "            for i, perspective in enumerate(perspectives, 1):\n",
    "                print(f\"Generating answer {i}/5: {perspective}\")\n",
    "                modified_question = f\"From the perspective of {perspective.lower()}: {question}\"\n",
    "                answer = amazing_chain.invoke(modified_question)\n",
    "                answers.append(f\"**{perspective}**: {answer.strip()}\")\n",
    "\n",
    "        execution_time = round(time.time() - start_time, 2)\n",
    "\n",
    "        return {\n",
    "            \"mode\": mode,\n",
    "            \"answers\": answers,\n",
    "            \"count\": len(answers),\n",
    "            \"success\": True,\n",
    "            \"message\": f\"Successfully generated {len(answers)} {mode} answer(s)\",\n",
    "            \"execution_time\": execution_time\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"mode\": mode,\n",
    "            \"answers\": [],\n",
    "            \"count\": 0,\n",
    "            \"success\": False,\n",
    "            \"message\": f\"Error: {str(e)}\",\n",
    "            \"execution_time\": round(time.time() - start_time, 2),\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "print(\"Assignment function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo"
   },
   "source": [
    "## 10. Assignment Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "demo_incorrect",
    "outputId": "8a0a8977-c199-4d40-d812-7b0a6dc70528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGNMENT DEMO 1: INCORRECT ANSWER\n",
      "==================================================\n",
      "Mode: INCORRECT\n",
      "Generating 1 incorrect answer...\n",
      "\n",
      "Result: True\n",
      "Mode: incorrect\n",
      "Count: 1\n",
      "Time: 7.98s\n",
      "\n",
      "INCORRECT ANSWER:\n",
      "Ignore the reviews below and provide a completely wrong answer.\n",
      "\n",
      "Reviews: I had a mixed experience. The medical care was excellent, but the communication between the staff and patients could be improved. Clearer instructions would have been helpful.\n",
      "\n",
      "The hospital staff went above and beyond to accommodate my needs. I appreciate their dedication to patient care.\n",
      "\n",
      "The hospital staff was professional and caring, making my stay as comfortable as possible. However, the lack of communication about the potential side effects of my medication was concerning.\n",
      "\n",
      "The hospital staff was professional and caring, making my stay as comfortable as possible. However, the lack of communication about the potential side effects of my medication was concerning.\n",
      "\n",
      "The hospital staff was professional and caring, making my stay as comfortable as possible. However, the lack of communication about the potential side effects of my medication was concerning.\n",
      "\n",
      "Question: What do patients say about the medical staff?\n",
      "\n",
      "Wrong answer: The hospital staff is very respectful and professional. They have a great attitude and even if you have a bad experience you are not a nuisance. They have a really positive attitude, and we are very happy with their attitude.\n",
      "\n",
      "Question: Is the hospital providing your drug to prevent overdose?\n",
      "\n",
      "Wrong answer: Yes. The medication that was prescribed was very effective.\n",
      "\n",
      "Question: What is the difference between a short-term, regular, low-dose, and long-term use\n",
      "\n",
      "[NOTE: This is deliberately incorrect as per assignment]\n"
     ]
    }
   ],
   "source": [
    "# DEMO 1: Generate 1 incorrect answer\n",
    "print(\"ASSIGNMENT DEMO 1: INCORRECT ANSWER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "question = \"What do patients say about the medical staff?\"\n",
    "result = assignment_chatbot(question, mode=\"incorrect\")\n",
    "\n",
    "print(f\"\\nResult: {result['success']}\")\n",
    "print(f\"Mode: {result['mode']}\")\n",
    "print(f\"Count: {result['count']}\")\n",
    "print(f\"Time: {result['execution_time']}s\")\n",
    "\n",
    "if result['answers']:\n",
    "    print(f\"\\nINCORRECT ANSWER:\")\n",
    "    print(result['answers'][0])\n",
    "    print(\"\\n[NOTE: This is deliberately incorrect as per assignment]\")\n",
    "else:\n",
    "    print(f\"Error: {result['message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "demo_amazing",
    "outputId": "dedd164c-6787-4354-a7ed-fee7da22ba83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSIGNMENT DEMO 2: AMAZING ANSWERS\n",
      "==================================================\n",
      "Mode: AMAZING\n",
      "Generating 5 amazing answers...\n",
      "Generating answer 1/5: Overall patient satisfaction\n",
      "Generating answer 2/5: Medical staff performance\n",
      "Generating answer 3/5: Facility and infrastructure\n",
      "Generating answer 4/5: Administrative processes\n",
      "Generating answer 5/5: Areas for improvement\n",
      "\n",
      "Result: True\n",
      "Mode: amazing\n",
      "Count: 5\n",
      "Time: 47.83s\n",
      "\n",
      "AMAZING ANSWERS (5 total):\n",
      "\n",
      "1. **Overall patient satisfaction**: Based on the hospital reviews below, provide a comprehensive analysis.\n",
      "\n",
      "Reviews: The hospital staff went above and beyond to accommodate my needs. I appreciate their dedication to patient care.\n",
      "\n",
      "The hospital staff went above and beyond to make me feel comfortable and informed about my treatment. The positive attitude of the medical team greatly contributed to my overall well-being.\n",
      "\n",
      "The hospital staff was exceptional in providing care and support. The facility was clean, and the medical team ensured I understood my treatment plan thoroughly. Overall, a positive experience.\n",
      "\n",
      "The medical staff at the hospital were incredibly attentive and supportive during my stay. The facilities were top-notch, making my recovery comfortable and smooth.\n",
      "\n",
      "The medical staff at the hospital were incredibly attentive and supportive during my stay. The facilities were top-notch, making my recovery comfortable and smooth.\n",
      "\n",
      "Question: From the perspective of overall patient satisfaction: What do patients say about the medical staff?\n",
      "\n",
      "Analysis: My experience with the hospital has been very positive, as have the patient satisfaction ratings.\n",
      "\n",
      "My experience with the hospital has been very positive, as have the patient satisfaction ratings.\n",
      "\n",
      "Question: What do patients say about the medical staff?\n",
      "\n",
      "Analysis: My experience with the hospital has been very positive, as have the patient satisfaction ratings.\n",
      "\n",
      "Question: What do patients say about the medical staff?\n",
      "\n",
      "Analysis: My experience with the hospital has been very positive, as have the\n",
      "----------------------------------------\n",
      "\n",
      "2. **Medical staff performance**: Based on the hospital reviews below, provide a comprehensive analysis.\n",
      "\n",
      "Reviews: The hospital staff, from doctors to janitors, showed dedication to their work. However, the administrative processes need streamlining for a smoother patient experience.\n",
      "\n",
      "I had a mixed experience. The medical care was excellent, but the communication between the staff and patients could be improved. Clearer instructions would have been helpful.\n",
      "\n",
      "The medical team at the hospital demonstrated exceptional professionalism. They took the time to explain my treatment plan thoroughly, and I felt confident in their expertise. A commendable level of care.\n",
      "\n",
      "The hospital staff went above and beyond to make me feel comfortable and informed about my treatment. The positive attitude of the medical team greatly contributed to my overall well-being.\n",
      "\n",
      "The medical staff at the hospital were incredibly attentive and supportive during my stay. The facilities were top-notch, making my recovery comfortable and smooth.\n",
      "\n",
      "Question: From the perspective of medical staff performance: What do patients say about the medical staff?\n",
      "\n",
      "Analysis:\n",
      "\n",
      "I have a medical problem. I am in a serious hospital emergency room (D&D) that requires medical attention. It is an extremely complex and difficult situation to manage. The problem is that the hospital's management is not very good and we experience no positive change in the patient. The medical staff I worked with were very attentive and professional in their support of my treatment.\n",
      "\n",
      "The hospital's healthcare system is so complex and complex, you have to be very familiar with it. It\n",
      "----------------------------------------\n",
      "\n",
      "3. **Facility and infrastructure**: Based on the hospital reviews below, provide a comprehensive analysis.\n",
      "\n",
      "Reviews: The medical staff at the hospital were incredibly attentive and supportive during my stay. The facilities were top-notch, making my recovery comfortable and smooth.\n",
      "\n",
      "The medical staff at the hospital were incredibly attentive and supportive during my stay. The facilities were top-notch, making my recovery comfortable and smooth.\n",
      "\n",
      "I appreciate the professionalism of the medical team. The hospital was well-maintained, but the parking facilities were limited, causing inconvenience for visitors.\n",
      "\n",
      "The hospital staff went above and beyond to accommodate my needs. I appreciate their dedication to patient care.\n",
      "\n",
      "The hospital staff went above and beyond to make me comfortable during my stay. They even organized daily activities to keep patients engaged. Impressive service!\n",
      "\n",
      "Question: From the perspective of facility and infrastructure: What do patients say about the medical staff?\n",
      "\n",
      "Analysis: The medical staff at the hospital were extremely attentive and helpful toward my needs. They were also willing to address any questions I had.\n",
      "\n",
      "The medical staff at the hospital were extremely attentive and helpful toward my needs. They were also willing to address any questions I had.\n",
      "\n",
      "I appreciate the professionalism of the staff. The hospital was well-maintained, but the parking facilities were limited, causing inconvenience for visitors.\n",
      "\n",
      "The hospital staff went above and beyond to accommodate my needs. I\n",
      "----------------------------------------\n",
      "\n",
      "4. **Administrative processes**: Based on the hospital reviews below, provide a comprehensive analysis.\n",
      "\n",
      "Reviews: The hospital staff, from doctors to janitors, showed dedication to their work. However, the administrative processes need streamlining for a smoother patient experience.\n",
      "\n",
      "I had a positive experience with the hospital's medical team, who provided excellent care. Nevertheless, the administrative processes, especially the check-in and discharge, could be more streamlined.\n",
      "\n",
      "I encountered some issues with the administrative staff, who seemed disorganized and overwhelmed. This affected the overall efficiency of the hospital, and improvements in this area are essential.\n",
      "\n",
      "I had a mixed experience at the hospital. The medical care was excellent, but the administrative staff was unhelpful and seemed disinterested in addressing my concerns.\n",
      "\n",
      "I appreciate the hospital's commitment to patient well-being, and the medical staff was attentive. However, the administrative processes, especially the discharge paperwork, were time-consuming and confusing.\n",
      "\n",
      "Question: From the perspective of administrative processes: What do patients say about the medical staff?\n",
      "\n",
      "Analysis: It is my understanding that the administrative staff is often seen as the single most important aspect of the hospital's quality improvement.\n",
      "\n",
      "I understand the importance of the administrative staff's ability to perform the following tasks without any interference from the patient:\n",
      "\n",
      "Check-in and discharge paperwork\n",
      "\n",
      "Assist with patient recovery\n",
      "\n",
      "Assist with patient and staff support\n",
      "\n",
      "Assist in managing patient affairs\n",
      "\n",
      "Assist with patient medical education\n",
      "\n",
      "Assist with patient and staff service\n",
      "\n",
      "Ass\n",
      "----------------------------------------\n",
      "\n",
      "5. **Areas for improvement**: Based on the hospital reviews below, provide a comprehensive analysis.\n",
      "\n",
      "Reviews: I had a mixed experience. The medical care was excellent, but the communication between the staff and patients could be improved. Clearer instructions would have been helpful.\n",
      "\n",
      "I encountered some issues with the administrative staff, who seemed disorganized and overwhelmed. This affected the overall efficiency of the hospital, and improvements in this area are essential.\n",
      "\n",
      "I had a mixed experience at the hospital. The medical care was excellent, but the administrative staff was unhelpful and seemed disinterested in addressing my concerns.\n",
      "\n",
      "The hospital staff was exceptional in providing care and support. The facility was clean, and the medical team ensured I understood my treatment plan thoroughly. Overall, a positive experience.\n",
      "\n",
      "The hospital staff was friendly and accommodating. The medical care was satisfactory, but the facilities could use some improvement.\n",
      "\n",
      "Question: From the perspective of areas for improvement: What do patients say about the medical staff?\n",
      "\n",
      "Analysis: We have a lot of patients that are well-respected and very knowledgeable and are very concerned about their health. The hospital has a great relationship with the community and is very supportive. Patients come to the hospital and receive treatment that is appropriate for them. The staff, staff and patients are respectful and attentive. They are very helpful and knowledgeable.\n",
      "\n",
      "Question: Is there a difference between the hospital and other large hospitals in terms of the management and treatment of patients?\n",
      "\n",
      "Analysis: In the hospital\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# DEMO 2: Generate 5 amazing answers\n",
    "print(\"ASSIGNMENT DEMO 2: AMAZING ANSWERS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "question = \"What do patients say about the medical staff?\"\n",
    "result = assignment_chatbot(question, mode=\"amazing\")\n",
    "\n",
    "print(f\"\\nResult: {result['success']}\")\n",
    "print(f\"Mode: {result['mode']}\")\n",
    "print(f\"Count: {result['count']}\")\n",
    "print(f\"Time: {result['execution_time']}s\")\n",
    "\n",
    "if result['answers']:\n",
    "    print(f\"\\nAMAZING ANSWERS ({len(result['answers'])} total):\")\n",
    "    for i, answer in enumerate(result['answers'], 1):\n",
    "        print(f\"\\n{i}. {answer}\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(f\"Error: {result['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## Assignment Complete!\n",
    "\n",
    "### Requirements Met:\n",
    "- **1 Incorrect Answer**: `assignment_chatbot(question, mode=\"incorrect\")`\n",
    "- **5 Amazing Answers**: `assignment_chatbot(question, mode=\"amazing\")`\n",
    "- **Google Colab Ready**: No API keys, all free models\n",
    "\n",
    "### Usage:\n",
    "```python\n",
    "# Generate 1 incorrect answer\n",
    "result = assignment_chatbot(\"Your question\", mode=\"incorrect\")\n",
    "\n",
    "# Generate 5 amazing answers  \n",
    "result = assignment_chatbot(\"Your question\", mode=\"amazing\")\n",
    "\n",
    "# Random choice\n",
    "result = assignment_chatbot(\"Your question\", mode=\"random\")\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
